3D human estimation : action understanding, surveillance(감시), human-robot interaction, motion capture 업무에 적용가능

다른 논문에서 인기있는 주제에 대한 광범위한 개요를 위해 다양한 설문조사를 진행한것을 참조하였다. 이전 접근방식(논문참조)은 비디오스트림, 멀티뷰카메라, depth image를 포함하여 고도로 센서가 적용된 환경을 사용하는 경우가 많다.

이전 접근방식에서는, 단일 2D RGB 이미지로 3D body pose를 추정하는 순수하고 도전적인 설정에 중점을 둔다.

본 논문의 핵심은 딥러닝을 통해 가능해진 2D 이미지를 이해하는 최근 발전을 활용하는 것임.

원래는 이미지 분류같은 대략적인 인식 작업을 위해 탐색되었지만 최근엔 네트워크 구조를 세분화된 human pose estimation으로 확장하여 작업이 2D 히트맵 예측중 하나로 공식화 되었음.

2D 인간 포즈 추정의 오랜 과제 중 하나는 자가폐색상태에서 포즈를 추정하는 것. 그동안은 self-occlusion 상태에서 2D로 포즈를 추정하지 못하였음.

실제로 2D가 아니라 3D 좌표 프레임을 작업하게 된 동기중에 하나가 바로 occlusion에 대한 추론이었음. 그러나 우리 눈에 띄는 결론 중 하나는 state-of-the-art 방법이 occlusion상태에서도 2D 포즈 추정 작업을 수행한다는 것임. 이것을 감안하면 남은 과제는 추정된 2D 관절에 대한 depth값을 예측하는 것임.

2D 대응으로부터 3D 구조를 추론하는 것은 컴퓨터비전에서 잘 연구된 문제인데, 종종 모션의 구조로 멀티 뷰 설정에서 해결되었음

monocular(= 외눈 = 단일이미지랑 같은의미인듯) 휴먼포즈측정의 맥락에서, 관련된 단서는 기하학적인거보단 의미론적인걸로 보임.

인체 측정, 운동학, 동적제약으로부터 나온 고수준의 지식기반으로 2D 뼈대로 3D 자세들을 추정할 수 있다.

데이터 기반 구조의 성공에 영감을 받아, 고수준의 제약조건에 대한 간단한 non-parametric 인코딩을 탐색한다 : 3D pose library가 주어지면, 가상 카메라 뷰에서 많은 수의 2D 프로젝션을 생성해야 한다는 제약조건 문제.
3D pose library -> 다량의 2D 프로젝션 생성

주어진 학습데이터 셋(2D,3D)과 2D 포즈 추정 알고리즘으로부터 예측이 주어지면, 3D 포즈 라이브러리에서 가장 가깝게 일치하는 2D 예측과 관련된 3D 포즈의 depth를 반환한다. 
-> 2D,3D데이터셋 + 2D포즈추정 알고리즘 CNN학습 -> 이미지가 주어지면, 2D포즈를 추정하고 3D포즈 라이브러리에 있는 2D포즈와 매칭시켜서 3D depth를 추정. -> 3D examplar에 의해 추가된 depth로 3D pose를 출력

일반화 : 3D주석의 어려움때문에 3D 레이블이 있는 학습 데이터 세트는 보통 실험실 환경에서 수집되는데, 2D 데이터세트는 더 다양한 경향이 있음. 2단계 파이프라인은 다른 단계에 대해 서로 다른 학습 세트를 사용하므로(컴퓨터구조) "in-the-wild" 이미지에서 3D 포즈를 예측할 수 있는 시스템이 생성된다.

평가 : 
1. 실제 이미지의 질적인 결과를 나타냈지만, Human 3.6M 데이터 세트로 수행한 method의 정량적 평가도 수행한다. 
2. 표준 train/test 프로토콜 분할을 따르지만, 분석결과 테스트 세트와 평가기준 측면에서 일관되지 않은 보고가 있는 것으로 나타났다. 결과를 최대한 투명하게 만들기 위해 찾을 수 있는 모든 측정 항목 및 분할에 대한 실적을 보고함
3. 놀라운 발견 중 하나는 간단한 파이프 라인의 인상적인 성능임. 기본적으로 모든 메트릭에 대한 모든 이전 작업을 능가함. 우리의 전체 파이프라인은 non-parametric 매칭 스텝이 주어졌더라도 200ms에서 2D 이미지가 제공된 3D 포즈를 반환한다. 마지막으로, 향후 진행상황을 촉진하기 위해 중간2D 표현과 3D제약조건의 데이터기반 인코딩 작업의 지속적인 이점을 보여주는 상한이 있는 추가 기준선에 대한 철저한 분석을 수행함.
